[{"content":"Introduction Within the developer community practice at Opencast software, once a month we are given a problem to solve. We call this the Learn by Doing initiative. These problems can range in difficulty, however, the premise is always the same: try and solve the problem in a language you\u0026rsquo;re not comfortable with or wish to learn more about. The idea behind this initiative is that it\u0026rsquo;s a great way to learn a new technology by just tackling a problem head on.\nFor July\u0026rsquo;s Learn by Doing problem, we were tasked with creating a REST API which returns river and rainfall levels. In this post, I\u0026rsquo;ll explore why I went with a Firebeetle 2 ESP32-E, how did I implement this solution using C++, and what I learnt from it.\nWithin this read, I\u0026rsquo;ll cover implementing the Flood API, the tools I used to implement it, and some of the challenges I faced along the way.\nThe problem As previously mentioned, the problem revolved around creating a REST API. To implement this, I was provided an OpenAPI 3.1 contract to follow. As for data for this API, I was also provided with an SQLite3 database containing data captured from Defra\u0026rsquo;s flood monitoring API that was captured every day over two years.\nThe only constraint to this (aside from following the OpenAPI specification) was that a test suite should pass when pointed to the REST API I have created. This test suite was created by Rob Anderson, who created this challenge.\nGiven I was allowed to use any technology I wished, I decided to tackle this project using a Firebeetle 2 ESP32-E microcontroller. While I\u0026rsquo;ve owned this microcontroller for a couple of years with the idea to incorporate it into a future Home Assistant setup, I hesitated due to not having a 3D printer to create protective enclosures for home deployment. This Learn by Doing challenge presented the perfect opportunity to work with the ESP32-E as the requirements of the problem (i.e. networking and database operations) aligned well with my future home automation plans.\nThis was an incredibly interesting challenge due to the nature of working with a Firebeetle 2 ESP32-E. Although this microcontroller is low-powered and slow compared to your usual host for a REST API, it is also very portable. The scope of the problem was to read river and rainfall levels from a database, yet it could easily be extended to write new flood information to the database. This could be done either from the existing Defra flood monitoring API, or even contribute new data by being deployed to a real river site and record data in real time.\nPlanning the environment and tooling Prior to diving into the Flood API implementation, I spent some time setting up my development environment and selecting the correct tools which would enable me to effectively create the Flood API. This section outlines the approach I took, the libraries I researched, and a couple of side tools I built along the way that ended up being quite useful, but not essential.\nThe development environment Before I started writing any code, I needed to decide what development environment I should use. The usual go-to option is the Arduino IDE—a beginner-friendly platform primarily designed for Arduino microcontrollers. Whilst it\u0026rsquo;s great for simple projects, it becomes quite limited when it comes to dependency management or more complex projects.\nAs an alternative, I opted for PlatformIO which builds on what Arduino IDE can do, but more. PlatformIO IDE tends to come as a plugin for CLion or Visual Studio Code rather than standalone software. Since I am comfortable with the JetBrains suite of products, being able to use CLion was perfect for me. The PlatformIO IDE also comes with tools for dependency management, unit testing via GoogleTest, and remote upload functionality.\nWorking remotely Although not essential for microcontroller development itself, PlatformIO’s remote capabilities turned out to be particularly useful for this project. By using PlatformIO Core (their CLI tool), I was able to connect my ESP32-E to a host machine (an old 2012 iMac in my case) and start a remote agent like this:\n1 % pui remote agent start With the agent running, I could upload builds, monitor output, and even run tests remotely from any other machine using the PlatformIO plugin. This setup was especially helpful since my main development machine is a MacBook Pro. It allowed me to work from anywhere without needing to have the microcontroller physically connected at all times. The main PlatformIO plugin doesn\u0026rsquo;t actually have options for remote development despite it being available in PlatformIO Core. Fortunately, the Platformio Plus plugin does.\nKey considerations The next step was to think about libraries I would need to use. I had four main considerations:\nHow do I expose a web app? How can I serialize an object into JSON? How can I read an SQLite3 database? How can I read a 22mb file on a microcontroller with only 4MB of flash memory? PlatformIO Home is a local user interface provided by the PlatformIO plugin that helps configure projects. The user interface includes a library search feature, which I used to address my first two considerations.\nFor exposing HTTP endpoints (consideration #1), I quickly found a few Arduino libraries that provide web server functionality. For JSON serialization (consideration #2), I came across ArduinoJson, which is widely regarded as the standard library for handling JSON on microcontrollers.\nAddressing considerations #3 and #4 required more effort. I knew I’d be reading my SQLite3 database from a MicroSD card, so I needed both a compatible MicroSD SPI module and a library capable of reading SQLite databases directly from external storage. After some research, I found esp32_arduino_sqlite3_lib, a library developed by siara-cc. It supports reading SQLite3 databases via various methods, including MicroSD cards via SPI. This library met both of my final requirements. I did find that this library is not found within PlatformIOs library search. However, I could import it into my project via git submodules.\nOther useful tools Although it was not required for this project, I took the opportunity to build a couple of additional tools that proved helpful during development of the Flood API.\nFirst, I wanted to experiment with my LCD1602 module. Getting feedback on the LCD in response to hitting various Flood API endpoints proved to be quite handy. This was especially useful for showcasing important runtime messages such as IP addresses without having to dig through logs. You\u0026rsquo;ll see it in various portions of my code with command like this:\n1 2 3 4 // Display IP and PORT number std::ostringstream portMessage; portMessage \u0026lt;\u0026lt; \u0026#34;Port: \u0026#34; \u0026lt;\u0026lt; std::to_string(flood::config::PORT); display-\u0026gt;displayText(WiFi.localIP().toString().c_str(), portMessage.str(), common::display::STICKY); I also created a cross-platform logger library. Usually, logging on a microcontroller looks like this:\n1 Serial.println(\u0026#34;My log!\u0026#34;); But since I wanted to run tests natively on my MacBook, I knew this default logging approach wouldn\u0026rsquo;t work outside of the microcontroller environment. So I built a logger that chooses the appropriate logging approach, including log levels depending on the target platform:\n1 LOG.debug_f(\u0026#34;My log: %d\u0026#34;, 125); With the LOG macro defined like so:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #if defined(ARDUINO) || defined(ESP32) #include \u0026#34;LoggerSerial.h\u0026#34; // Uses Serial.printLn() for logging #define LOG jbriggs::common::logger::LoggerSerial::getInstance() #else #include \u0026#34;Logger.h\u0026#34; // Uses cout for logging #define LOG jbriggs::common::logger::Logger::getInstance() #endif Whilst these tools weren\u0026rsquo;t part of the core Flood API functionality, they were valuable during development and may be moved into a common library for reuse in future projects. I won\u0026rsquo;t be covering them in further detail here though.\nImplementation Now that I had my development environment setup, it was time to start the implementation of the Flood API. Within this section, I\u0026rsquo;ll go through the various steps I took to implement the Flood API. This will include setting up the device and its connections, connecting to the SQLite3 database, and creating a response which will be returned to the client.\nInitial setup Before touching any code, I needed to setup my ESP32-E microcontroller by connecting the MicroSD SPI module to the correct pins. The pinout for the ESP32-E is can be found on the DFRobot website. The MicroSD SPI module I have contains six pins which all need to be connected to the ESP32-E.\nAll but one of the pins have a specific pin they should be connected to on the ESP32-E.\nMicroSD Module Pin Name Description Connecting ESP32 Pin CS Chip Select Pin 4 (Used as input or output) SCK Serial Clock Standard SPI SCK pin MOSI Master Out, Slave In Standard SPI MOSI pin MISO Master In, Slave Out Standard SPI MISO pin VCC 5V Power Standard VCC pin GND Ground Standard GRN pin Connecting to my local network Since the device needs to be accessible from within my home network, I needed to setup my WiFi connection. I used the Arduino WifiClient library to do this. This library provides a simple way to setup WiFi credentials, and then automatically connect to the network:\n1 2 3 4 5 6 7 8 WiFiClass::mode(WIFI_STA); WiFi.begin(flood::config::WIFI_SSID, flood::config::WIFI_PASSWORD); while (WiFiClass::status() != WL_CONNECTED) { delay(500); display-\u0026gt;displayText(\u0026#34;Connecting..\u0026#34;, common::display::FLASH); } LOG.debug_f(\u0026#34;Connected to WiFi: %s\u0026#34;, WiFi.localIP().toString().c_str()); I also displayed the IP address of the ESP32-E on the LCD, and the port number of the API:\n1 2 3 4 5 // Display IP and PORT number std::ostringstream portMessage; portMessage \u0026lt;\u0026lt; \u0026#34;Port: \u0026#34; \u0026lt;\u0026lt; std::to_string(flood::config::PORT); display-\u0026gt;displayText(WiFi.localIP().toString().c_str(), portMessage.str(), common::display::STICKY); Connecting to SQLite3 As previously mentioned, I found a crucial SQLite3 library specifically for ESP32 microcontrollers which supports accessing SQLite3 database files via SD cards. A lot of my implementation here follows a good example which the library provides. Before actually reading the data from the database file, some setup is required.\nTo begin, I needed to initialize the SPI bus, and SD library. I also make sure that the SD card is readable:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 void FloodRepository::init() { // Step 1: Initialize SPI and SD LOG.info(\u0026#34;Initializing FloodRepository\u0026#34;); LOG.debug(\u0026#34;Beginning SPI\u0026#34;); SPI.begin(); LOG.debug(\u0026#34;Beginning SD \u0026#34;); while (!SD.begin(config::MICRO_SD_CS_PIN)) { LOG.error(\u0026#34;Card Mount Failed\u0026#34;); } uint8_t cardType = SD.cardType(); if (cardType == CARD_NONE) { LOG.error(\u0026#34;No SD card attached\u0026#34;); throw std::runtime_error(\u0026#34;No SD card attached\u0026#34;); } ... Next, I just make sure that the file I am going to be reading the flood data from is actually readable:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // --- Continued: Still inside FloodRepository::init() --- // Step 2: Check the database file exists if (SD.exists(this-\u0026gt;m_dbPath)) { LOG.debug_f(\u0026#34;Database file \u0026#39;%s\u0026#39; exists on SD card\u0026#34;, this-\u0026gt;m_dbPath); File file = SD.open(this-\u0026gt;m_dbPath); LOG.debug_f(\u0026#34;File size: %d\u0026#34;, file.size()); file.close(); } else { LOG.error(\u0026#34;Database file not found on SD card\u0026#34;); } ... Now that I know the SD card is mounted, and the database file is read, it\u0026rsquo;s time to initialize the SQLite3 library:\n1 2 3 4 5 6 7 8 9 10 11 12 // --- Continued: Still inside FloodRepository::init() --- // Step 3: Initialize SQLite3 LOG.info(\u0026#34;Initializing SQLite3...\u0026#34;); int initialize = sqlite3_initialize(); if (initialize != SQLITE_OK) { LOG.error_f(\u0026#34;Failed to initialize SQLite3: %s\u0026#34;, initialize); throw std::runtime_error(\u0026#34;Failed to initialize SQLite3\u0026#34;); } ... Once the library has been initialized, I open the database file:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // --- Continued: Still inside FloodRepository::init() --- // Step 4: Open database file LOG.debug(\u0026#34;Opening DB...\u0026#34;); std::stringstream vfsPath; vfsPath \u0026lt;\u0026lt; \u0026#34;/sd\u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_dbPath; if (openDb(vfsPath.str(), \u0026amp;m_floodDb) != SQLITE_OK) { LOG.error(\u0026#34;Failed to open database\u0026#34;); throw std::runtime_error(\u0026#34;Failed to open database\u0026#34;); } LOG.info_f(\u0026#34;Connected to database!\u0026#34;); ... Once that is done, the database is actually in a usable state. there is one more thing I do during setup however to better optimize my future calls to the database, and that is cache all station names found within the database to avoid doing additional calls:\n1 2 3 4 5 6 7 8 9 10 11 12 13 // --- Continued: Still inside FloodRepository::init() --- // Step 5: Cache station names LOG.debug(\u0026#34;Caching station names\u0026#34;); auto stationNames = this-\u0026gt;getAllStations(); if (stationNames.empty()) { LOG.error(\u0026#34;Failed to get station names\u0026#34;); throw std::runtime_error(\u0026#34;Failed to get station names\u0026#34;); } LOG.info(\u0026#34;Completed initialization for FloodRepository\u0026#34;); } Mapping to something useful Since my API needs to return JSON, I decided to create an intermediary service to map the objects returned by my repository layer into JSON. Using ArduinoJson made this process painless and straightforward:\n1 2 3 4 5 6 7 8 9 10 11 12 13 JsonDocument doc; for (const auto\u0026amp; rainfallReading : rainfallReadings) { JsonDocument reading; reading[\u0026#34;timestamp\u0026#34;] = rainfallReading.timestamp; reading[\u0026#34;level\u0026#34;] = rainfallReading.level; reading[\u0026#34;station\u0026#34;] = rainfallReading.station; if (!doc[\u0026#34;readings\u0026#34;].add(reading)) { LOG.error(\u0026#34;Failed to add reading\u0026#34;); throw std::runtime_error(\u0026#34;Failed to add reading\u0026#34;); } } To convert this JsonDocument into an easy-to-read JSON output, ArduinoJson provides a handy function:\n1 2 3 std::string json; serializeJsonPretty(doc, json); LOG.debug(json); Flood routes Setting up WebServer Within the Arduino core libraries for ESP32 is the WebServer class. This class is a \u0026ldquo;dead simple web-server\u0026rdquo; that supports GET and POST HTTP methods; although limited, it is perfect and lightweight for my use case of having a read-only API.\nThe setup for this web server is basic; all you need is to register a handler to a URI:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FloodRoutes::FloodRoutes(common::display::IDisplay* display, db::IFloodRepository* flood_repository, mapper::IFloodMapper* flood_mapper) : m_server(config::PORT), m_display(display), m_floodRepository(flood_repository), m_floodMapper(flood_mapper) { // Setup routes LOG.debug(\u0026#34;Setting up routes...\u0026#34;); // GET: /river m_server.on(\u0026#34;/river\u0026#34;, HTTP_GET, [this] { // Handles the response this-\u0026gt;river(); }); ... For handling a URI with a path parameter, UriBraces becomes useful as a matcher, and then the path parameter can be extracted via the WebServer:\n1 2 3 4 5 6 7 8 9 10 11 12 13 // --- Continued: Still inside FloodRoutes::FloodRoutes() --- // GET: /rainfall/{stationName} m_server.on(UriBraces(\u0026#34;/rainfall/{}\u0026#34;), HTTP_GET, [this] { const auto pathArg = m_server.pathArg(0); const std::string stationName(pathArg.c_str(), pathArg.length()); // Handles the response this-\u0026gt;rainfallStation(stationName); }); ... Finally, with WebServer setup, the server can be started:\n1 2 3 4 5 6 // --- Continued: Still inside FloodRoutes::FloodRoutes() --- // Begin server LOG.debug(\u0026#34;Starting server in FloodRoutes\u0026#34;); m_server.begin(); } Returning content on WebServer With WebServer now initialized, I needed to send a response to the client. As you may have seen in the Setting up WebServer, as part of handling a URI, I called a function for both /river and /rainfall/{stationName} which handles the response. Both functions are similar in functionality due to how much logic is delegated to the repository layer and mappers.\nThe first step is to get any request parameters passed as part of the request. I created a handy function which returns the value of a request parameter to help facilitate this. The getQueryParameter function checks if a request param exists, and extracts it if it does. If the request param does not exist, then return a default value:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 std::string FloodRoutes::getQueryParameter(const std::string\u0026amp; param, const std::string\u0026amp; defaultValue) { // Build string for LCD std::stringstream paramDisplay; paramDisplay \u0026lt;\u0026lt; \u0026#34;Param \u0026#34; \u0026lt;\u0026lt; param; // Check if request param is found on request const String paramName(param.c_str()); if (!m_server.hasArg(paramName)) { LOG.debug_f(\u0026#34;Param %s not found\u0026#34;, param.c_str()); displayParamOnLCD(paramDisplay.str(), defaultValue.empty() ? \u0026#34;EMPTY\u0026#34; : defaultValue); // Return the default value if request param does not exist return defaultValue.empty() ? \u0026#34;\u0026#34; : defaultValue; } // Extract request param value const auto paramValue = m_server.arg(paramName); std::string result(paramValue.c_str(), paramValue.length()); displayParamOnLCD(paramDisplay.str(), result); return result; } With getQueryParameter(), I could get the request parameters at the start of a request:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void FloodRoutes::river() { LOG.info(\u0026#34;/river requested\u0026#34;); m_display-\u0026gt;displayText(\u0026#34;Calling\u0026#34;, \u0026#34;/river\u0026#34;, common::display::FLASH); // Get request parameters // Get the date parameter const std::string date = getQueryParameter(\u0026#34;start\u0026#34;); // Get limit parameter with default value, and convert to int const int limit = std::stoi(getQueryParameter(\u0026#34;page\u0026#34;, \u0026#34;1\u0026#34;)); // Get page parameter with default value, and convert to int const int pagesize = std::stoi(getQueryParameter(\u0026#34;pagesize\u0026#34;, \u0026#34;12\u0026#34;)); ... Next, data needs to be fetched from the flood repository:\n1 2 3 4 5 6 // --- Continued: Still inside FloodRoutes::river() --- const std::vector\u0026lt;db::RiverReading\u0026gt; readings = m_floodRepository-\u0026gt;getRiverReadings(date, limit, pagesize); ... Finally, using my mapper, I could turn this data into JSON and return a response using WebServer:\n1 2 3 4 5 6 7 8 9 10 11 12 // --- Continued: Still inside FloodRoutes::river() --- // Convert to JSON const JsonDocument doc = m_floodMapper-\u0026gt;getFloodData(readings); std::string json; serializeJsonPretty(doc, json); const char* result = json.c_str(); return m_server.send(200, \u0026#34;application/json\u0026#34;, result); } The function for getting rainfalls for a station is very similar, only it has the addition of the path parameter from the URI /rainfall/{stationName}, and a quick check to ensure that the station passed exists:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 void FloodRoutes::rainfallStation(const std::string\u0026amp; stationName) { // Get path param station name std::stringstream fullPath; fullPath \u0026lt;\u0026lt; \u0026#34;/rainfall/\u0026#34; \u0026lt;\u0026lt; stationName; LOG.info_f(\u0026#34;/rainfall/{station} requested using %s\u0026#34;, stationName); m_display-\u0026gt;displayText(\u0026#34;Calling\u0026#34;, fullPath.str(), common::display::FLASH); // You can validate against your known stations if (!m_floodRepository-\u0026gt;stationExists(stationName)) { m_server.send(404, \u0026#34;application/json\u0026#34;, R\u0026#34;({\u0026#34;error\u0026#34;: \u0026#34;Invalid station name. Station not found.\u0026#34;})\u0026#34;); return; } // Get request parameters // Get the date parameter const std::string date = getQueryParameter(\u0026#34;start\u0026#34;, \u0026#34;2022-12-25\u0026#34;); // Get limit parameter with default value const int limit = std::stoi(getQueryParameter(\u0026#34;page\u0026#34;, \u0026#34;1\u0026#34;)); // Get page parameter with default value const int pagesize = std::stoi(getQueryParameter(\u0026#34;pagesize\u0026#34;, \u0026#34;12\u0026#34;)); const std::vector\u0026lt;db::RainfallReading\u0026gt; rainfall_readings = m_floodRepository-\u0026gt;getStationRainfallReadings(stationName, date, limit, pagesize); // Convert to JSON const JsonDocument doc = m_floodMapper-\u0026gt;getRainfallReadings(rainfall_readings); std::string json; serializeJsonPretty(doc, json); return m_server.send(200, \u0026#34;application/json\u0026#34;, json.c_str()); } What setbacks did I have As this was my first embedded project, the implementation wasn\u0026rsquo;t entirely straightforward. A couple of things set myself back and made me reconsider approaches at times. Whilst these issues didn\u0026rsquo;t stop the project from completing, it definitely would shape how I design future projects on the ESP32 series of microcontrollers.\nPartition tables The next issue I had with the Flood API was storage. My Firebeetle 2 ESP32-E only contains 4MB of flash memory. This does not mean I have 4MB to play with.\nThis default partition table ends allowing slightly more than 1MB of storage for your main app. Turns out for the Flood API and the number of dependencies I was using, I needed slightly more than the default:\n1 2 3 RAM: [== ] 17.5% (used 57412 bytes from 327680 bytes) Flash: [==========] 115.2% (used 1509853 bytes from 1310720 bytes) Error: The program size (1509853 bytes) is greater than maximum allowed (1310720 bytes) To fix this, you can define your own partition table if you know what you\u0026rsquo;re doing, however there are quite a few default partition tables you can select from which probably fit all possible needs.:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 jamie.briggs@G0GG60253H LearnByDoing % ls -l $HOME/.platformio/packages/framework-arduinoespressif32/tools/partitions total 216 -rw-r--r--@ 1 jamie.briggs staff 377 6 Jun 2024 app3M_fat9M_16MB.csv -rw-r--r--@ 1 jamie.briggs staff 447 6 Jun 2024 app3M_fat9M_fact512k_16MB.csv -rw-r--r--@ 1 jamie.briggs staff 374 6 Jun 2024 app3M_spiffs9M_fact512k_16MB.csv -rw-r--r--@ 1 jamie.briggs staff 125 6 Jun 2024 bare_minimum_2MB.csv -rw-r--r--@ 1 jamie.briggs staff 8192 6 Jun 2024 boot_app0.bin -rw-r--r--@ 1 jamie.briggs staff 304 6 Jun 2024 default_16MB.csv -rw-r--r--@ 1 jamie.briggs staff 304 6 Jun 2024 default_8MB.csv -rw-r--r--@ 1 jamie.briggs staff 305 6 Jun 2024 default_ffat_8MB.csv -rw-r--r--@ 1 jamie.briggs staff 304 6 Jun 2024 default_ffat.csv -rw-r--r--@ 1 jamie.briggs staff 3072 6 Jun 2024 default.bin -rw-r--r--@ 1 jamie.briggs staff 304 6 Jun 2024 default.csv -rw-r--r--@ 1 jamie.briggs staff 378 6 Jun 2024 ffat.csv -rw-r--r--@ 1 jamie.briggs staff 259 6 Jun 2024 huge_app.csv -rw-r--r--@ 1 jamie.briggs staff 307 6 Jun 2024 large_fat_32MB.csv -rw-r--r--@ 1 jamie.briggs staff 305 6 Jun 2024 large_ffat_8MB.csv -rw-r--r--@ 1 jamie.briggs staff 307 6 Jun 2024 large_littlefs_32MB.csv -rw-r--r--@ 1 jamie.briggs staff 304 6 Jun 2024 large_spiffs_16MB.csv -rw-r--r--@ 1 jamie.briggs staff 305 6 Jun 2024 large_spiffs_8MB.csv -rw-r--r--@ 1 jamie.briggs staff 216 6 Jun 2024 max_app_8MB.csv -rw-r--r--@ 1 jamie.briggs staff 303 6 Jun 2024 min_spiffs.csv -rw-r--r--@ 1 jamie.briggs staff 265 6 Jun 2024 minimal.csv -rw-r--r--@ 1 jamie.briggs staff 260 6 Jun 2024 no_ota.csv -rw-r--r--@ 1 jamie.briggs staff 260 6 Jun 2024 noota_3g.csv -rw-r--r--@ 1 jamie.briggs staff 334 6 Jun 2024 noota_3gffat.csv -rw-r--r--@ 1 jamie.briggs staff 334 6 Jun 2024 noota_ffat.csv -rw-r--r--@ 1 jamie.briggs staff 320 6 Jun 2024 rainmaker.csv The default partition table is split into six partitions:\nPartition Name Type Size Purpose nvs data 20KB Non-volatile storage. Usually holds Wi-Fi credentials, or user settings. otadata data 8KB Stores over-the-air update metadata. app0 app 1.25MB First firmware slot. Contains the application the user has created (Flood API). app1 app 1.25MB Second firmware slot. Used when updating. spiffs Data 1.375MB File system storage, used for storing assets like logs or data. coredump Data 64KB Reserved for crash dump data. The key thing here is that there is support for over-the-air updates. Whilst useful, for this project it\u0026rsquo;s unnecessary and I could take that storage for my own use. I also didn\u0026rsquo;t need all the space on spiffs partition as my SQLite3 database would be stored on a MicroSD card anyway. I went for huge_app.csv as it fit all of my needs:\nPartition Name Type Size Purpose nvs data 20KB Non-volatile storage. Usually holds Wi-Fi credentials, or user settings. otadata data 8KB Stores over-the-air update metadata. Not used due to lack of second app partition. app0 app 3MB The only firmware slot. Contains the application the user has created (Flood API). spiffs Data 896KB File system storage, used for storing assets like logs or data. coredump Data 64KB Reserved for crash dump data. This partition table was then added to my .platformio:\n1 2 3 4 5 6 7 [ env:firebeetle2_esp32e ] platform = espressif32 board = dfrobot_firebeetle2_esp32e framework = arduino test_framework = googletest monitor_speed = 115200 board_build.partitions = huge_app.csv If I needed even more space for the application, I could have created a custom partition table file and removed otadata and spiffs entirely. However, the defaults provided in huge_app.csv were more than sufficient for the projects needs.\nThis then allows the Flood API to fit on the ESP32-E with plenty of room. Although this meant that I couldn\u0026rsquo;t update the app remotely in a deployed setting, for this project it wasn\u0026rsquo;t in scope. This does, however, highlight a crucial drawback to this specific microcontroller when it comes to memory.\nSQLite3 compatibility issues When I first set up the repository layer, I ran into an issue with reading the SQLite3 database file. Initially, I suspected it was my own error, but testing with an example database from the SQLite3 library showed that the issue was specific to the flood database file I was using.\nI knew the file itself was fine - others working on the same challenge were using it without issues - so my next suspicion was a compatibility problem with the library. Checking the database version confirmed the file was built with SQLite 3.43.2:\n1 2 % file flood.db flood.db: SQLite 3.x database, last written using SQLite version 3043002, writer version 2, read version 2, unused bytes 12, file counter 2378, database pages 6170, cookie 0x18, schema 4, UTF-8, version-valid-for 2378 The library I used was also based on this version, so I expected it to work. However my application logs showed that this was not the case:\n1 2 3 4 5 6 7 8 9 10 11 [DEBUG] Beginning SPI [DEBUG] Beginning SD [DEBUG] Database file \u0026#39;/flood.db\u0026#39; exists on SD card [DEBUG] File size: 25272320 [INFO] Initializing SQLite3... [DEBUG] Opening DB... [INFO] Opened database successfully: /sd/flood.db [INFO] Connected to database! [DEBUG] Caching station names [DEBUG] Preparing query: SELECT * FROM StationNames [ERROR] Failed to prepare statement: file is not a database Locally, flood.db opened without issue. So I decided to recreate it myself. First, I dumped the database:\n1 % sqlite3 flood.db .dump \u0026gt; flood_dump.sql I then downloaded SQLite 3.43.2, and built it from source:\n1 2 3 % cd sqlite-version-3.43.2/ sqlite-version-3.43.2 % ./configure sqlite-version-3.43.2 % make Finally, I created a new database from the dump:\n1 sqlite3 flood_recreated.db \u0026lt; flood_dump.sql Using this newly created version of the flood database resolved the problem:\n1 2 3 4 5 6 7 8 9 [INFO] Initializing SQLite3... [DEBUG] Opening DB... [INFO] Opened database successfully: /sd/flood_recreated.db [INFO] Connected to database! [DEBUG] Caching station names [DEBUG] Preparing query: SELECT * FROM StationNames [DEBUG] Stepping through statement [DEBUG] Finalizing. Found 11 results. [INFO] Completed initialization for FloodRepository I\u0026rsquo;m still not so sure as to why the original file failed with this library, but recreating it allowed me to move forward.\nWhilst I did manage to get this working in the end, I did spend a large amount of time exploring other database options. This was mainly due to both space constraints, which I explained in the Partition tables section. At the time, I did not think I could modify partition tables, so I instead tried to find something more lightweight.\nWhilst debugging the storage issues I was having, I briefly explored connecting to an external MySQL database. The idea was that offloading the search functionality to an external server would mean that the library I\u0026rsquo;d use for connecting to the database would be more lightweight. I did manage to get this working, however, it still didn\u0026rsquo;t fix the underlying storage limitations. In retrospect, if I had fixed the partition tables before trying this, it would\u0026rsquo;ve worked completely fine as my tests confirmed. Although this idea was scrapped, it\u0026rsquo;s handy to know it\u0026rsquo;s possible to use an external MySQL database in a REST API on a microcontroller.\nThe final implementation After a lot of work, the final Flood API was complete. With the ESP32-E started, I could connect to the API which I had implemented.\nWith my ESP32-E powered on, I could make a request to the /river endpoint with three parameters:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 % curl -X GET \u0026#34;http://192.168.1.249:80/river?start=2022-12-25\u0026amp;page=1\u0026amp;pagesize=12\u0026#34; { \u0026#34;readings\u0026#34;: [ { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T00:00:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.864 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T00:15:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.859 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T00:30:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.857 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T00:45:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.854 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T01:00:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.853 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T01:15:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.85 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T01:30:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.85 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T01:45:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.85 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T02:00:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.85 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T02:15:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.85 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T02:30:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.85 }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2022-12-25T02:45:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.853 } ] } And I could make a request to the /rainfall/{stationName} endpoint with a parth variable, and two request parameters:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 % curl -X GET \u0026#34;http://192.168.1.249:80/rainfall/acomb-codlaw-hill?start=2024-02-01\u0026amp;page=101\u0026amp;pagesize=6\u0026#34; { \u0026#34;readings\u0026#34;: [ { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-09T01:30:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.2, \u0026#34;station\u0026#34;: \u0026#34;acomb-codlaw-hill\u0026#34; }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-09T01:45:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.2, \u0026#34;station\u0026#34;: \u0026#34;acomb-codlaw-hill\u0026#34; }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-09T02:00:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.2, \u0026#34;station\u0026#34;: \u0026#34;acomb-codlaw-hill\u0026#34; }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-09T02:15:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.2, \u0026#34;station\u0026#34;: \u0026#34;acomb-codlaw-hill\u0026#34; }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-09T02:30:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.2, \u0026#34;station\u0026#34;: \u0026#34;acomb-codlaw-hill\u0026#34; }, { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-09T02:45:00Z\u0026#34;, \u0026#34;level\u0026#34;: 0.2, \u0026#34;station\u0026#34;: \u0026#34;acomb-codlaw-hill\u0026#34; } ] } To ensure the API worked as expected, I ran the provided test suite, which I could call to know if what I\u0026rsquo;ve done was working:\n1 % ./FloodApiTests http://192.168.1.249:80 On first inspection the test suite works as expected, however, I did notice that some tests were failing. After some investigation, I found that they were failing due to performance issues and the test suite was timing out. With this in mind, I decided to ignore those failing tests and call it a success. This timeout is only due to multiple requests being made at once, and the ESP32-E is not powerful enough to handle them. I also verified this by hitting the endpoint manually.\nWhat I learned The purpose of the Learn by Doing initiative is to undertake a project in a language or technology that would challenge you. This is a great way to learn a new skill or technique, and this project was no exception. I gained a lot of experience working with the ESP32-E, understanding what it can do, and how to use it effectively. The main goal of using this microcontroller was to explore how it could be used in a home automation context, and I\u0026rsquo;m happy to know that it could be used in this way.\nThe first and biggest thing I learned was how many libraries exist on the PlatformIO library registry, and without a couple of libraries supporting the ESP32-E, I would\u0026rsquo;ve struggled to get this project working. I wanted to give mention to the following libraries which helped me get this project working:\nArduinoJson LiquidCrystal ESP32 WebServer ESP32_Arduino_SQLite3_Lib GoogleTest The next takeaway was the understanding of using external storage. I knew that the flash memory of an ESP32-E was limited and always will be. Knowing that I could use an external storage device, such as a MicroSD card, allowed me to explore how I could use this to store data. In this project I used it to store the SQLite3 database and could easily write to that database as well if I were to record data instead.\nThe last thing I learnt was just how straightforward it is to set up a REST API on an ESP32-E. Using the ESP32 WebServer library-as seen within the flood routes section-I was able to quickly build an API which could be used to retrieve data from the SQLite3 database. While most of my use cases for the ESP32-E revolve around home automation, adding WebServer to my devices would make it easy to query their status and gather additional information.\nWhat I\u0026rsquo;d do differently The biggest thing I would do differently if I were to do this project again is to use a different microcontroller. The Firebeetle 2 ESP32-E is a great microcontroller, yet the version I own has storage limitations which make it unsuitable for this kind of application; although I was able to fit the application on the microcontroller, I had to disable any over-the-air update functionality to do so, making it impossible to update the application remotely. There are other models of this same microcontroller with more flash memory, specifically a 16MB variant, which would allow me to hold the entire application without compromise.\nIf I wasn\u0026rsquo;t limiting myself to what database solution I should use, I would\u0026rsquo;ve perhaps went with a MySQL database. Realistically, if I were setting up a home automation system, I\u0026rsquo;d like all the devices to be connected and storing data in the same database to keep all the data in one place. It would also mean that not every device I own would need to have a MicroSD card, making it more cost-effective.\nWrap up I would like to thank to Rob Anderson for creating July\u0026rsquo;s Learn by doing challenge, it was incredibly interesting! This project was a great way to understand embedded systems, and I\u0026rsquo;m looking forward to exploring more of the capabilities of the Firebeetle 2 ESP32-E in the future.\n","date":"2025-08-14T20:38:00Z","image":"https://jbriggs.dev/p/esp32-flood-api/cover_hu_2844cd003fe1280f.jpeg","permalink":"https://jbriggs.dev/p/esp32-flood-api/","title":"ESP32-E Flood REST API"},{"content":"First I\u0026rsquo;d like to say hello, so I guess hello! My plan for this year is to grow my social media presence a bit more. So to do this, I\u0026rsquo;ve created this blog. I don\u0026rsquo;t have a proper plan as to what I\u0026rsquo;ll post on here, but I do aim to post content which I find beneficial, or things I have learnt. Although the majority of my work is software development focused, that doesn\u0026rsquo;t necessarily mean that all of my posts will be related; they could just be tech related or things I found cool!\nWhat I do know, is that I have a bunch of projects which I\u0026rsquo;ll be posting on here from my old portfolio. My old portfolio is currently sat in limbo behind the paywall which is Adobe so it would be good to revisit some of my older work! Expect to see some of this work in the near future!\n","date":"2025-01-29T18:48:00Z","image":"https://jbriggs.dev/p/hello/cover_hu_44c16eea823c7688.jpeg","permalink":"https://jbriggs.dev/p/hello/","title":"Hello!"},{"content":"For anyone who is unaware, Ludum Dare is a bi-annual game jam where participants take part in creating a game for a common theme which tends to be announced the moment the event starts. From this point, participants receive 48 hours to create and submit their game.\nFor Ludum Dare 44, the theme was \u0026ldquo;Your life is currency\u0026rdquo;. With this being my first game jam, I didn\u0026rsquo;t rush into creating the game and I instead brainstormed for probably a bit too long which wasted most of first day. In hindsight, I should\u0026rsquo;ve just started creating something, even if it was just the basic structure of a video game (i.e. menus and game systems).\nOnce I had an idea, I finally spent the remaining time rushing a game out. I learnt a fair amount about Unity development (this was my first in depth foray into Unity) and I published something which I think was in theme. I also learnt quite a lot about deploying and publishing embedded Unity games using itch.io.\nThe game I finally created was called \u0026ldquo;Nine Lives\u0026rdquo;. Given the theme of the game jam was \u0026ldquo;Your life is currency\u0026rdquo;, I decided I could play on the common expression that cats have 9 lives. The game itself is a bit of a linear roguelike, inspired by earlier The Legend of Zelda games, where you go from room to room. This game was an endless runner and consisted of yourself running around as a cat shooting balls of wool at oversized rats. In the game, you can score points by killing rats, and sometimes collect more hearts to keep your life up.\nIn the end, although I did follow the theme slightly, it wasn\u0026rsquo;t a very strong submission. There wasn\u0026rsquo;t really much of an idea of currency, and although you had a life total in game, it was more of a health bar as opposed to a currency of sorts. I did however learn quite a lot about game development, and how Unity handles collisions and scenes. I also learnt more about the sprite program Asprite. This was my first ever instance of using this program, and I thoroughly recommend it to create in game assets in pixel form as it\u0026rsquo;s super easy to use!\nBelow is my submission for the Ludum Dare 44!\nThere are three takeaways which I learnt when it comes to tackling future game jams. The first takeaway is to not spend too much time trying to think of the best idea to submit something. 48 hours is really not much time for creating a game, so if you don\u0026rsquo;t have an idea, at least start creating something.\nThe second thing I took away from this experience was that you don\u0026rsquo;t need to create something perfect. In my head for this submission, I wanted a completed game to show off, so I went for an endless runner based game. However after looking at other submissions, other games were essentially tech demos, or a first level of sorts. Due to this, they were much more refined.\nFinally, the main takeaway was that game jams are there to learn something new. It\u0026rsquo;s okay to not submit something as really, a game jam is just a fun excuse to learn something new and create something along the way!\n","date":"2019-04-14T00:00:00Z","image":"https://jbriggs.dev/p/2019-04-ludum-dare-44/cover_hu_9e9262c248eab0e.png","permalink":"https://jbriggs.dev/p/2019-04-ludum-dare-44/","title":"Ludum Dare 44 - Nine Lives"},{"content":"For an assignment during my degree in Computer Games Programming, I was tasked with making a game in which I had to write the AI for a team of bots to beat another team of bots with badly written AI. This was all done in C++ and within a 2D game engine created by the module tutor Chris Rook.\nThe game was essentially a 5 v 5 between two teams fighting over domination points. There is no end to the game, just two scores which explain which team had the better AI. Everything was already created before starting the AI such as the map, where the domination points were, the teams and the various rules which needed to be followed. All there was left to do was write a AI which could beat the enemies teams pre-made AI.\nThe AI was split into two different sections; the generation of a navmesh in which the bots could use the navmesh to work out how to get from point A to point B, and then the making of the bots core AI which told the bot when to find a domination point, when to retreat and get ammo, and when to attack.\nTo start with, since the map was pre-made by Chris, all there was to do was to generate a navmesh. The navmesh was made by passing a rectangle into a function which partitions the rectangle into 4 smaller rectangles if the original rectangle is overlapping an obstacle. If the rectangle either doesn’t overlap and obstacle or gets too small, a node is placed and saved into a list of nodes.\nThen once all the nodes are placed, edges are created between nodes which can see each other in which paths are made which can reach each other. By doing this, a network of paths is then created and the bots finally have a navmesh which can be traversed. This navmesh can then be used within the A* path-finding algorithm later.\nThe second part of the bots AI was then started once the map had been made, and that began with behaviours. These behaviours were actions which the bots could do; seek, flee, arrive, evade, pursue, path find and wall evade. The first five were more advanced and were turned on in specific moments during the path find behaviour (when following points in a path, the bot would seek the next node, when arriving at the last point in a path, it would use the arrive behaviour). The wall avoid behaviour was essentially turned on at all times to make sure a bot would not get stuck on a wall.\nThe most advanced behaviour of these would be the path finding behaviour, in which a path is followed using the seek and arrive behaviours. However for this to work, a path must be found first. Using the navmesh which was made before, an A* algorithm is used to find the shortest path from A to B given two coordinates.\nAfter this, a function was made which combined all of the different behaviours to make one acceleration vector which the bot used given whichever behaviour is being used at that current time. An easy explanation of this would be that the bot is heading towards a goal, but a wall is in the way. So the acceleration of the seek is added to the acceleration of the wall avoid. In doing so, the bot would still head towards the goal, even if the bot had to slightly turn away from a wall to avoid hitting it.\nNext to make use of these behaviours, different states was made. A state within the program would in the end give a bot a specific task. In this case, three states was made; capture in which a bot will go and find a domination point and capture it, attack in which an enemy is close and the bot will fight the enemy, and reload in which a bot will go find a reload point and restock on ammo. With this done, the bots were complete and could win in a game. However, more could be done to improve the program.\nMulti-Threading is the idea that a task within a program or application would run a process off the main thread the program runs on an multitasks calculations. This is massively useful in terms of making sure a program is still responsive whilst working out a huge problem or loading a big file (no one wants a program which freezes and becomes unresponsive for a few seconds as it is unprofessional).\nThis was implemented into the program after finding out that the program would stutter whenever a bot needed to do some path finding. With the A* algorithm looping through hundreds of nodes within the game, it can take a lot of processing power and freeze the game slightly. This was proven by recording the update times, and the first update in the game finding 5 different paths in one update cycle (due to having 5 bots per team) was found to be quite large compared to an average frame. Therefore, it was made so whenever a path was to be worked out with the A* algorithm, it would be done on a separate thread and the bot would wait until the path was then found. This fixed any stutters within the program, and especially within the start of the game. The first frame then returned back to an average frame time and any stutters were completely eliminated. Adding more bots to each team even showed that it had fixed the problem as even with 100 bots finding a path, no pauses or stutters was shown as it were previously even with just 5 bots.\nThe other improvement made within the game was the use of networking. Despite the game only being two teams of bots and not two human players, it was still done. The game was made so that one computer running the game could act as the host, and another computer running the game could act as the client and connect to the host. The host would then send over all the bots position data, ammo and when the bot was shooting so then everything which happened on the host computer would occur on the client computer. This was all done through bit packing showed how a client on any game could spectate another game with just basic information.\nAfter the two improvements was done, the game was then finished complete with a working AI which used A* path finding and states, multi-threading and networking. As a year-long project, a lot was learnt in undertaking this project including how A*, multi threading and networking all work.\n","date":"2018-01-19T00:00:00Z","image":"https://jbriggs.dev/p/2018-01-ai/ai-project-1_hu_555752fec3fdd8fd.jpg","permalink":"https://jbriggs.dev/p/2018-01-ai/","title":"AI, Multi-Threading and Networking Bot Game"},{"content":" This post was written 9th February 2025, as a retrospective post to port my portfolio from Adobe Portfolio to this blog.\nOne of the modules in my Computer Games Programming Degree at Northumbria University involved myself creating a game using the PlayStation 4 development kits. A friend of mine had the initiatice to recreate a video game from his childhood. The marking criteria for this module only involved gameplay elements such as loading .obj files, rendering textures and AI. This meant no marks were ever given for creativity and story telling; theoretically I could\u0026rsquo;ve produced unplayable rubbish, but if it had aspects of gameplay like AI or even 3D rendering, it would\u0026rsquo;ve scored marks. So I copied his thought process because if I recreated a game from my childhood as well, I would spend less time focusing on what to create and just focusing on gameplay mechanics.\nWith this in mind, I needed to pick something which wasn\u0026rsquo;t too complicated, but also something I would be interested in recreating; if I thoroughly into recreating a game I loved, chances are I would also not mind spending hours creating the game as a passion project. In the end, I went with Star Fox 64 (I knew it as Lyat Wars growing up due to Nintendo wanting to avoid confusion with a German company named \u0026ldquo;StarVox\u0026rdquo;).\nTo learn how to create games for the PlayStation 4, there was a very helpful tutorial given to the students within my course which went into how to load and render .obj files, to shader work and it\u0026rsquo;s relativity to GLSL, to how to program the controller and it\u0026rsquo;s behaviour. A lot of the work which was done within this tutorial was very much a tutorial on how to write a game in the same style as a lecturer, meaning everyone had the same game structure, but it was a very good start into the various aspects of creating a 3D game from scratch. Retrospectively, the PlayStation 4 actually did a lot of the rending for you with it\u0026rsquo;s own SDK compared to OpenGL, but you still had to provide the SDK with your game data and logic. However with the basics understood, there was enough to make a start on the Star Fox 64 remake. Not too important, but games written to use the official PlayStation 4 development kits were written in C++.\nWhat I remembered most of Star Fox 64 from my childhood was how fun it was to control the player ship, and who can forget performing a barrel roll! So I primarily focused on the handling of the player ship. I also knew I only had time to create a tech demo of sorts. The majority of the original game is actually an on the rails shooter, however I figured at the time it was easier to just program a free flying ship just like in the boss areas of the game. This way I could focus on the ship controls, and then later do the compilated rails shooter stuff if I had time; I didn\u0026rsquo;t so good call!\nIn the end, I ended up creating something which consisted of a flat plane where enemies would constantly spawn in the middle, and the player could shoot them down. The Player also had health and when you died, it would be game over. It was quite a simple demo, but the work to get to that point was extensive. I have linked a clip of the game below. Unfortunately the clip doesn\u0026rsquo;t show all the maneuvers you could do in the game and I no longer have access to the PlayStation 4 dev kits to record the game again.\nIn the future, I would like to see if I could play the game in a PlayStation 4 emulator . This way I could look back on my code and perhaps have a retrospection on what I\u0026rsquo;ve learnt since working on this project.\nThis project was done under NDA. I still have the source code for it, but until there is a clear indication that it\u0026rsquo;s okay to release the source code, it will remain private.\n","date":"2017-07-25T00:00:00Z","image":"https://jbriggs.dev/p/2017-07-lyat-wars/lyat-wars-ps4_hu_c6ef77780a001cfe.png","permalink":"https://jbriggs.dev/p/2017-07-lyat-wars/","title":"Star Fox PS4 remake"}]